{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1e47ef",
   "metadata": {},
   "source": [
    "# RVX Data Catalog & Exploration\n",
    "\n",
    "Comprehensive exploration of all datasets in the RVX folders:\n",
    "- `traveling_survey/` - National travel survey data\n",
    "- `zonal_register_data/` - Zonal statistical data (SDAT files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82197e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/anderskielland/Documents/Synthetic data/code/synthetic-lab\n",
      "RVX path: /Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx\n",
      "Path exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# Setup\n",
    "from synlab.utils import get_project_root\n",
    "\n",
    "project_root = get_project_root()\n",
    "rvx_path = project_root / 'data' / 'raw' / 'population' / 'rvx'\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"RVX path: {rvx_path}\")\n",
    "print(f\"Path exists: {rvx_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd9cb88",
   "metadata": {},
   "source": [
    "## 1. Folder Overview\n",
    "\n",
    "List all files and their sizes in both folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e045c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìÅ TRAVELING_SURVEY\n",
      "================================================================================\n",
      "\n",
      "Total files: 8\n",
      "\n",
      "File listing:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Filemail.com - Nasjonal RVU akkumulert data.zip                  228.44 MB  .zip\n",
      "Filemail.com - RVU 2025.zip                                      128.01 MB  .zip\n",
      "Nasjonal_RVU_PERSON_Nov26_0901.sav                                63.65 MB  .sav\n",
      "Nasjonal_RVU_REISER_Nov26_0901.sav                                64.36 MB  .sav\n",
      "Oppdatert skjema RVU_2025.docx                                     0.37 MB  .docx\n",
      "RVU 2019-2024 Personfil Vektet 251125.sav                         93.56 MB  .sav\n",
      "RVU 2019_2024 Reisefil 251107.sav                                134.88 MB  .sav\n",
      "Sp√∏rreskjema_RVU_2021_2024.docx                                    0.20 MB  .docx\n",
      "\n",
      "By extension:\n",
      "  .docx             2 files\n",
      "  .sav              4 files\n",
      "  .zip              2 files\n",
      "\n",
      "================================================================================\n",
      "üìÅ ZONAL_REGISTER_DATA\n",
      "================================================================================\n",
      "\n",
      "Total files: 28\n",
      "\n",
      "File listing:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sdat1_d2024_g2020.dbf                                              4.42 MB  .dbf\n",
      "sdat1_d2024_g2021.dbf                                              4.42 MB  .dbf\n",
      "sdat1_d2024_g2023.dbf                                              4.43 MB  .dbf\n",
      "sdat1_d2024_g2024.dbf                                              4.43 MB  .dbf\n",
      "sdat2_data2020_delomr.xlsx                                         3.42 MB  .xlsx\n",
      "sdat2_data2020_grunnkrets.xlsx                                    25.69 MB  .xlsx\n",
      "sdat3_d2023x_g2020.dbf                                             2.38 MB  .dbf\n",
      "sdat3_d2023x_g2021.dbf                                             2.38 MB  .dbf\n",
      "sdat3_d2023x_g2023.dbf                                             2.38 MB  .dbf\n",
      "sdat3_d2023x_g2024.dbf                                             2.38 MB  .dbf\n",
      "sdat4_d2024_g2020.dbf                                              2.60 MB  .dbf\n",
      "sdat4_d2024_g2021.dbf                                              2.60 MB  .dbf\n",
      "sdat4_d2024_g2023.dbf                                              2.60 MB  .dbf\n",
      "sdat4_d2024_g2024.dbf                                              2.60 MB  .dbf\n",
      "sdat5_d2023_g2020.dbf                                              0.55 MB  .dbf\n",
      "sdat5_d2023_g2021.dbf                                              0.55 MB  .dbf\n",
      "sdat5_d2023_g2023.dbf                                              0.55 MB  .dbf\n",
      "sdat5_d2023_g2024.dbf                                              0.55 MB  .dbf\n",
      "sdat71_NB2023_grk2020_2020.dbf                                     0.39 MB  .dbf\n",
      "sdat7_d20xx_g2020_ikke_pkost.dbf                                   0.66 MB  .dbf\n",
      "sdat7_d20xx_g2021_ikke_pkost.dbf                                   0.66 MB  .dbf\n",
      "sdat7_d20xx_g2023_ikke_pkost.dbf                                   0.66 MB  .dbf\n",
      "sdat7_d20xx_g2024_ikke_pkost.dbf                                   0.66 MB  .dbf\n",
      "sdat8_d2024_g2020.dbf                                              0.87 MB  .dbf\n",
      "sdat8_d2024_g2021.dbf                                              0.87 MB  .dbf\n",
      "sdat8_d2024_g2023.dbf                                              0.87 MB  .dbf\n",
      "sdat8_d2024_g2024.dbf                                              0.87 MB  .dbf\n",
      "sdat_6_areal_g2020.dbf                                             3.98 MB  .dbf\n",
      "\n",
      "By extension:\n",
      "  .dbf             26 files\n",
      "  .xlsx             2 files\n"
     ]
    }
   ],
   "source": [
    "def get_folder_structure(folder_path):\n",
    "    \"\"\"\n",
    "    Walk through folder and collect all files with metadata.\n",
    "    Returns list of dicts with file info.\n",
    "    \"\"\"\n",
    "    files_info = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Skip .DS_Store and other system files\n",
    "        files = [f for f in files if not f.startswith('.')]\n",
    "        \n",
    "        for file in files:\n",
    "            file_path = Path(root) / file\n",
    "            size_bytes = os.path.getsize(file_path)\n",
    "            size_mb = size_bytes / (1024 * 1024)\n",
    "            \n",
    "            rel_path = file_path.relative_to(folder_path)\n",
    "            \n",
    "            files_info.append({\n",
    "                'filename': file,\n",
    "                'relative_path': str(rel_path),\n",
    "                'full_path': str(file_path),\n",
    "                'size_bytes': size_bytes,\n",
    "                'size_mb': round(size_mb, 2),\n",
    "                'extension': Path(file).suffix\n",
    "            })\n",
    "    \n",
    "    return sorted(files_info, key=lambda x: x['filename'])\n",
    "\n",
    "# Explore both folders\n",
    "folders = ['traveling_survey', 'zonal_register_data']\n",
    "all_files = {}\n",
    "\n",
    "for folder_name in folders:\n",
    "    folder_path = rvx_path / folder_name\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìÅ {folder_name.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    files = get_folder_structure(folder_path)\n",
    "    all_files[folder_name] = files\n",
    "    \n",
    "    print(f\"\\nTotal files: {len(files)}\")\n",
    "    print(f\"\\nFile listing:\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for f in files:\n",
    "        print(f\"{f['filename']:<60} {f['size_mb']:>10.2f} MB  {f['extension']}\")\n",
    "    \n",
    "    # Summary by extension\n",
    "    by_ext = defaultdict(int)\n",
    "    for f in files:\n",
    "        by_ext[f['extension']] += 1\n",
    "    \n",
    "    print(f\"\\nBy extension:\")\n",
    "    for ext, count in sorted(by_ext.items()):\n",
    "        print(f\"  {ext if ext else '[no ext]':<15} {count:>3} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ced7e",
   "metadata": {},
   "source": [
    "## 2. Explore Data File Types\n",
    "\n",
    "Understand the structure of different data formats (.dbf, .sav, .xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a435442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì pyreadstat already installed\n",
      "‚úì openpyxl already installed\n",
      "‚úì dbfread already installed\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries for reading different formats\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['pyreadstat', 'openpyxl', 'dbfread']\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úì {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "        print(f\"‚úì {package} installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6120731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìä DBF FILES (zonal_register_data)\n",
      "================================================================================\n",
      "\n",
      "Total DBF files: 26\n",
      "‚úì DBF schema extraction complete\n"
     ]
    }
   ],
   "source": [
    "# Try reading different file types\n",
    "import pyreadstat\n",
    "from dbfread import DBF\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "file_schemas = {}\n",
    "\n",
    "# 1. DBF files (zonal_register_data)\n",
    "print(\"=\"*80)\n",
    "print(\"üìä DBF FILES (zonal_register_data)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "dbf_files = [f for f in all_files['zonal_register_data'] if f['extension'] == '.dbf']\n",
    "print(f\"\\nTotal DBF files: {len(dbf_files)}\")\n",
    "\n",
    "for dbf_file in dbf_files:\n",
    "    key = dbf_file['relative_path']\n",
    "    sample_path = dbf_file['full_path']\n",
    "    \n",
    "    try:\n",
    "        table = DBF(sample_path, encoding='latin-1')\n",
    "        columns_detail = [\n",
    "            {\n",
    "                'name': field.name,\n",
    "                'type': field.type,\n",
    "                'length': field.length,\n",
    "                'decimals': field.decimal_count\n",
    "            }\n",
    "            for field in table.fields\n",
    "        ]\n",
    "        \n",
    "        rows = len(table)\n",
    "        file_schemas[key] = {\n",
    "            'file_type': 'DBF',\n",
    "            'rows': rows,\n",
    "            'columns': len(columns_detail),\n",
    "            'columns_detail': columns_detail\n",
    "        }\n",
    "    except Exception as e:\n",
    "        file_schemas[key] = {\n",
    "            'file_type': 'DBF',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"‚úì DBF schema extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eed3d519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä SPSS SAV FILES (traveling_survey)\n",
      "================================================================================\n",
      "\n",
      "Total SAV files: 4\n",
      "‚úì SAV schema extraction complete\n"
     ]
    }
   ],
   "source": [
    "# 2. SPSS/SAV files (traveling_survey)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä SPSS SAV FILES (traveling_survey)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sav_files = [f for f in all_files['traveling_survey'] if f['extension'].lower() == '.sav']\n",
    "print(f\"\\nTotal SAV files: {len(sav_files)}\")\n",
    "\n",
    "for sav_file in sav_files:\n",
    "    key = sav_file['relative_path']\n",
    "    try:\n",
    "        try:\n",
    "            df, meta = pyreadstat.read_sav(sav_file['full_path'], row_limit=100)\n",
    "            rows = meta.number_rows if hasattr(meta, 'number_rows') else len(df)\n",
    "        except TypeError:\n",
    "            df, meta = pyreadstat.read_sav(sav_file['full_path'])\n",
    "            rows = len(df)\n",
    "        \n",
    "        columns_detail = [\n",
    "            {'name': col, 'type': str(df[col].dtype)}\n",
    "            for col in df.columns\n",
    "        ]\n",
    "        \n",
    "        file_schemas[key] = {\n",
    "            'file_type': 'SAV (SPSS)',\n",
    "            'rows': rows,\n",
    "            'columns': len(df.columns),\n",
    "            'columns_detail': columns_detail\n",
    "        }\n",
    "    except Exception as e:\n",
    "        file_schemas[key] = {\n",
    "            'file_type': 'SAV (SPSS)',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"‚úì SAV schema extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d065687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä EXCEL FILES (.xlsx)\n",
      "================================================================================\n",
      "\n",
      "Total XLSX files: 2\n",
      "‚úì XLSX schema extraction complete\n"
     ]
    }
   ],
   "source": [
    "# 3. XLSX files\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä EXCEL FILES (.xlsx)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "xlsx_files = [f for f in all_files['zonal_register_data'] if f['extension'].lower() == '.xlsx']\n",
    "print(f\"\\nTotal XLSX files: {len(xlsx_files)}\")\n",
    "\n",
    "for xlsx_file in xlsx_files:\n",
    "    key = xlsx_file['relative_path']\n",
    "    try:\n",
    "        wb = load_workbook(xlsx_file['full_path'], read_only=True, data_only=True)\n",
    "        sheets_info = []\n",
    "        \n",
    "        for sheet_name in wb.sheetnames:\n",
    "            ws = wb[sheet_name]\n",
    "            header_row = next(ws.iter_rows(min_row=1, max_row=1, values_only=True), [])\n",
    "            header = [str(h) if h is not None else '' for h in header_row]\n",
    "            \n",
    "            sheets_info.append({\n",
    "                'sheet': sheet_name,\n",
    "                'rows': ws.max_row,\n",
    "                'columns': len(header),\n",
    "                'column_names': header\n",
    "            })\n",
    "        \n",
    "        file_schemas[key] = {\n",
    "            'file_type': 'XLSX',\n",
    "            'sheets': sheets_info\n",
    "        }\n",
    "    except Exception as e:\n",
    "        file_schemas[key] = {\n",
    "            'file_type': 'XLSX',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"‚úì XLSX schema extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d22c878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üì¶ ARCHIVES\n",
      "================================================================================\n",
      "\n",
      "Total ZIP files: 2\n",
      "\n",
      "üîç Filemail.com - Nasjonal RVU akkumulert data.zip (228.44 MB)\n",
      "  Contains 2 files:\n",
      "    - RVU 2019-2024 Personfil Vektet 251125.sav             93.56 MB\n",
      "    - RVU 2019_2024 Reisefil 251107.sav                    134.88 MB\n",
      "\n",
      "üîç Filemail.com - RVU 2025.zip (128.01 MB)\n",
      "  Contains 2 files:\n",
      "    - Nasjonal_RVU_PERSON_Nov26_0901.sav                    63.65 MB\n",
      "    - Nasjonal_RVU_REISER_Nov26_0901.sav                    64.36 MB\n"
     ]
    }
   ],
   "source": [
    "# 4. ZIP and other archives\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üì¶ ARCHIVES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "zip_files = [f for f in all_files['traveling_survey'] if f['extension'].lower() == '.zip']\n",
    "print(f\"\\nTotal ZIP files: {len(zip_files)}\")\n",
    "\n",
    "import zipfile\n",
    "for zip_file in zip_files:\n",
    "    print(f\"\\nüîç {zip_file['filename']} ({zip_file['size_mb']:.2f} MB)\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_file['full_path'], 'r') as z:\n",
    "            file_list = z.namelist()\n",
    "            print(f\"  Contains {len(file_list)} files:\")\n",
    "            for fname in sorted(file_list)[:10]:  # First 10\n",
    "                info = z.getinfo(fname)\n",
    "                size_mb = info.file_size / (1024*1024)\n",
    "                print(f\"    - {fname:<50} {size_mb:>8.2f} MB\")\n",
    "            if len(file_list) > 10:\n",
    "                print(f\"    ... and {len(file_list) - 10} more files\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Could not read: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afafbb43",
   "metadata": {},
   "source": [
    "## 3. Generate Data Catalog Markdown\n",
    "\n",
    "Create a comprehensive markdown document of all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4de4b51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated catalog (first 2000 chars):\n",
      "# RVX Data Catalog\n",
      "\n",
      "**Generated:** 2026-02-02 16:34:31\n",
      "\n",
      "Complete inventory and documentation of all datasets in the RVX folders.\n",
      "\n",
      "## Overview\n",
      "\n",
      "The RVX folder contains two main data sources:\n",
      "\n",
      "1. **traveling_survey/** - National travel survey (RVU - Reisevaneunders√∏kelsen)\n",
      "2. **zonal_register_data/** - Zonal statistical data (SDAT files) from Statistics Norway\n",
      "\n",
      "## Folder Structure\n",
      "\n",
      "\n",
      "### traveling_survey/\n",
      "\n",
      "**National Travel Survey Data (RVU)**\n",
      "\n",
      "Contains survey responses about travel behavior of Norwegian households.\n",
      "- **Format:** SPSS (.sav), ZIP archives, documentation (.docx)\n",
      "- **Source:** Statistics Norway (SSB)\n",
      "- **Coverage:** Years 2019-2025\n",
      "\n",
      "**Statistics:**\n",
      "- Total files: 8\n",
      "- Total size: 713.47 MB\n",
      "\n",
      "**Files:**\n",
      "\n",
      "| Filename | Size (MB) | Type | Rows | Columns |\n",
      "|----------|-----------|------|------|---------|\n",
      "| `Filemail.com - Nasjonal RVU akkumulert data.zip` | 228.44 | .zip | n/a | n/a |\n",
      "| `Filemail.com - RVU 2025.zip` | 128.01 | .zip | n/a | n/a |\n",
      "| `Filemail.com - RVU 2025/Nasjonal_RVU_PERSON_Nov26_0901.sav` | 63.65 | .sav | 100 | 453 |\n",
      "| `Filemail.com - RVU 2025/Nasjonal_RVU_REISER_Nov26_0901.sav` | 64.36 | .sav | 100 | 226 |\n",
      "| `Oppdatert skjema RVU_2025.docx` | 0.37 | .docx | n/a | n/a |\n",
      "| `Filemail.com - Nasjonal RVU akkumulert data/RVU 2019-2024 Personfil Vektet 251125.sav` | 93.56 | .sav | n/a | n/a |\n",
      "| `Filemail.com - Nasjonal RVU akkumulert data/RVU 2019_2024 Reisefil 251107.sav` | 134.88 | .sav | 100 | 103 |\n",
      "| `Sp√∏rreskjema_RVU_2021_2024.docx` | 0.20 | .docx | n/a | n/a |\n",
      "\n",
      "\n",
      "### zonal_register_data/\n",
      "\n",
      "**Zonal Statistical Data (SDAT)**\n",
      "\n",
      "Grid-based statistical data at different geographic resolutions.\n",
      "- **Format:** DBF (dBase), XLSX\n",
      "- **Source:** Statistics Norway (TRAMOD/RVX)\n",
      "- **Coverage:** Multiple grid resolutions (grunnkrets, delomr, etc.)\n",
      "- **Data years:** 2020-2024\n",
      "\n",
      "**Statistics:**\n",
      "- Total files: 28\n",
      "- Total size: 79.42 MB\n",
      "\n",
      "**Files:**\n",
      "\n",
      "| Filename | Size (MB) | Type | Rows | Columns |\n",
      "|----------|-----------|------|------|---------|\n",
      "| `sdat1_d2024_g2020\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive markdown catalog\n",
    "catalog_md = f\"\"\"# RVX Data Catalog\n",
    "\n",
    "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Complete inventory and documentation of all datasets in the RVX folders.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The RVX folder contains two main data sources:\n",
    "\n",
    "1. **traveling_survey/** - National travel survey (RVU - Reisevaneunders√∏kelsen)\n",
    "2. **zonal_register_data/** - Zonal statistical data (SDAT files) from Statistics Norway\n",
    "\n",
    "## Folder Structure\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Add folder summaries\n",
    "for folder_name in folders:\n",
    "    files = all_files[folder_name]\n",
    "    total_size = sum(f['size_mb'] for f in files)\n",
    "    \n",
    "    catalog_md += f\"\\n### {folder_name}/\\n\\n\"\n",
    "    \n",
    "    if folder_name == 'traveling_survey':\n",
    "        catalog_md += \"\"\"**National Travel Survey Data (RVU)**\n",
    "\n",
    "Contains survey responses about travel behavior of Norwegian households.\n",
    "- **Format:** SPSS (.sav), ZIP archives, documentation (.docx)\n",
    "- **Source:** Statistics Norway (SSB)\n",
    "- **Coverage:** Years 2019-2025\n",
    "\n",
    "\"\"\"\n",
    "    else:\n",
    "        catalog_md += \"\"\"**Zonal Statistical Data (SDAT)**\n",
    "\n",
    "Grid-based statistical data at different geographic resolutions.\n",
    "- **Format:** DBF (dBase), XLSX\n",
    "- **Source:** Statistics Norway (TRAMOD/RVX)\n",
    "- **Coverage:** Multiple grid resolutions (grunnkrets, delomr, etc.)\n",
    "- **Data years:** 2020-2024\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    catalog_md += f\"**Statistics:**\\n\"\n",
    "    catalog_md += f\"- Total files: {len(files)}\\n\"\n",
    "    catalog_md += f\"- Total size: {total_size:.2f} MB\\n\\n\"\n",
    "    \n",
    "    # List files\n",
    "    catalog_md += \"**Files:**\\n\\n\"\n",
    "    catalog_md += \"| Filename | Size (MB) | Type | Rows | Columns |\\n\"\n",
    "    catalog_md += \"|----------|-----------|------|------|---------|\\n\"\n",
    "    \n",
    "    for f in files:\n",
    "        schema = file_schemas.get(f['relative_path'], {})\n",
    "        rows = schema.get('rows', 'n/a')\n",
    "        cols = schema.get('columns', 'n/a')\n",
    "        catalog_md += f\"| `{f['relative_path']}` | {f['size_mb']:.2f} | {f['extension'] or 'dir'} | {rows} | {cols} |\\n\"\n",
    "    \n",
    "    catalog_md += \"\\n\"\n",
    "\n",
    "# Add detailed schema section\n",
    "catalog_md += \"## Dataset Schemas\\n\\n\"\n",
    "\n",
    "for folder_name in folders:\n",
    "    catalog_md += f\"### {folder_name}/\\n\\n\"\n",
    "    files = all_files[folder_name]\n",
    "    \n",
    "    for f in files:\n",
    "        key = f['relative_path']\n",
    "        schema = file_schemas.get(key)\n",
    "        if not schema:\n",
    "            continue\n",
    "        \n",
    "        catalog_md += f\"#### {f['filename']}\\n\\n\"\n",
    "        catalog_md += f\"- **Path:** `{key}`\\n\"\n",
    "        catalog_md += f\"- **Type:** {schema.get('file_type', 'Unknown')}\\n\"\n",
    "        \n",
    "        if 'error' in schema:\n",
    "            catalog_md += f\"- **Error:** {schema['error']}\\n\\n\"\n",
    "            continue\n",
    "        \n",
    "        if schema.get('file_type') == 'XLSX':\n",
    "            catalog_md += f\"- **Sheets:** {len(schema.get('sheets', []))}\\n\\n\"\n",
    "            for sheet in schema.get('sheets', []):\n",
    "                catalog_md += f\"  - **Sheet:** {sheet['sheet']}\\n\"\n",
    "                catalog_md += f\"    - Rows: {sheet['rows']}\\n\"\n",
    "                catalog_md += f\"    - Columns: {sheet['columns']}\\n\"\n",
    "                catalog_md += f\"    - Column names: {', '.join(sheet['column_names'])}\\n\"\n",
    "            catalog_md += \"\\n\"\n",
    "        else:\n",
    "            catalog_md += f\"- **Rows:** {schema.get('rows', 'n/a')}\\n\"\n",
    "            catalog_md += f\"- **Columns:** {schema.get('columns', 'n/a')}\\n\\n\"\n",
    "            \n",
    "            columns_detail = schema.get('columns_detail', [])\n",
    "            if columns_detail:\n",
    "                catalog_md += \"**Column details:**\\n\\n\"\n",
    "                catalog_md += \"| Column | Type |\\n\"\n",
    "                catalog_md += \"|--------|------|\\n\"\n",
    "                for col in columns_detail:\n",
    "                    col_name = col.get('name', '')\n",
    "                    col_type = col.get('type', '')\n",
    "                    catalog_md += f\"| {col_name} | {col_type} |\\n\"\n",
    "                catalog_md += \"\\n\"\n",
    "\n",
    "print(\"Generated catalog (first 2000 chars):\")\n",
    "print(catalog_md[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f07b935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved catalog to: /Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/docs/DATA_CATALOG_RVX.md\n",
      "\n",
      "File size: 66.75 KB\n"
     ]
    }
   ],
   "source": [
    "# Save the catalog markdown\n",
    "catalog_path = project_root / 'docs' / 'DATA_CATALOG_RVX.md'\n",
    "catalog_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(catalog_path, 'w') as f:\n",
    "    f.write(catalog_md)\n",
    "\n",
    "print(f\"‚úì Saved catalog to: {catalog_path}\")\n",
    "print(f\"\\nFile size: {catalog_path.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f6a29",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "Check what we've discovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8206cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA CATALOG SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìÅ traveling_survey:\n",
      "   Files: 8\n",
      "   Total size: 713.47 MB\n",
      "   Types: .docx(2), .sav(4), .zip(2)\n",
      "\n",
      "üìÅ zonal_register_data:\n",
      "   Files: 28\n",
      "   Total size: 79.42 MB\n",
      "   Types: .dbf(26), .xlsx(2)\n",
      "\n",
      "‚úÖ Full catalog saved to: /Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/docs/DATA_CATALOG_RVX.md\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA CATALOG SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for folder_name in folders:\n",
    "    files = all_files[folder_name]\n",
    "    total_size = sum(f['size_mb'] for f in files)\n",
    "    \n",
    "    print(f\"\\nüìÅ {folder_name}:\")\n",
    "    print(f\"   Files: {len(files)}\")\n",
    "    print(f\"   Total size: {total_size:.2f} MB\")\n",
    "    \n",
    "    by_ext = defaultdict(int)\n",
    "    for f in files:\n",
    "        by_ext[f['extension']] += 1\n",
    "    \n",
    "    # Build type summary string\n",
    "    type_summary = ', '.join(f\"{ext or '[none]'}({c})\" for ext, c in sorted(by_ext.items()))\n",
    "    print(f\"   Types: {type_summary}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Full catalog saved to: {catalog_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc75b434",
   "metadata": {},
   "source": [
    "## 5. Create Pretty Outputs\n",
    "\n",
    "Convert the markdown catalog to HTML and PDF formats for viewing/printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d19a72db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Rendering markdown preview...\n"
     ]
    }
   ],
   "source": [
    "# 1. Preview in notebook (renders the markdown beautifully)\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"üìñ Rendering markdown preview...\")\n",
    "# display(Markdown(catalog_md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a75526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved styled HTML to: /Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/docs/DATA_CATALOG_RVX.html\n",
      "   Open in browser: file:///Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/docs/DATA_CATALOG_RVX.html\n",
      "   File size: 103.71 KB\n"
     ]
    }
   ],
   "source": [
    "# 2. Create styled HTML version (beautiful webpage)\n",
    "# Convert markdown to HTML first\n",
    "import markdown\n",
    "html_content = markdown.markdown(catalog_md, extensions=['tables'])\n",
    "\n",
    "# Create full HTML page with styling (using f-string to avoid format conflicts)\n",
    "full_html = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>RVX Data Catalog</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            max-width: 1200px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            background-color: #f5f5f5;\n",
    "        }}\n",
    "        .container {{\n",
    "            background-color: white;\n",
    "            padding: 40px;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        h1 {{\n",
    "            color: #2c3e50;\n",
    "            border-bottom: 3px solid #3498db;\n",
    "            padding-bottom: 10px;\n",
    "        }}\n",
    "        h2 {{\n",
    "            color: #34495e;\n",
    "            margin-top: 30px;\n",
    "            border-bottom: 2px solid #ecf0f1;\n",
    "            padding-bottom: 8px;\n",
    "        }}\n",
    "        h3 {{\n",
    "            color: #7f8c8d;\n",
    "        }}\n",
    "        table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin: 20px 0;\n",
    "            background-color: white;\n",
    "        }}\n",
    "        th {{\n",
    "            background-color: #3498db;\n",
    "            color: white;\n",
    "            padding: 12px;\n",
    "            text-align: left;\n",
    "            font-weight: 600;\n",
    "        }}\n",
    "        td {{\n",
    "            padding: 10px 12px;\n",
    "            border-bottom: 1px solid #ecf0f1;\n",
    "        }}\n",
    "        tr:hover {{\n",
    "            background-color: #f8f9fa;\n",
    "        }}\n",
    "        code {{\n",
    "            background-color: #f4f4f4;\n",
    "            padding: 2px 6px;\n",
    "            border-radius: 3px;\n",
    "            font-family: 'Courier New', monospace;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        ul {{\n",
    "            padding-left: 25px;\n",
    "        }}\n",
    "        li {{\n",
    "            margin: 8px 0;\n",
    "        }}\n",
    "        .generated-date {{\n",
    "            color: #95a5a6;\n",
    "            font-style: italic;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        {html_content}\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save HTML file\n",
    "html_path = project_root / 'docs' / 'DATA_CATALOG_RVX.html'\n",
    "with open(html_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(full_html)\n",
    "\n",
    "print(f\"‚úÖ Saved styled HTML to: {html_path}\")\n",
    "print(f\"   Open in browser: file://{html_path}\")\n",
    "print(f\"   File size: {html_path.stat().st_size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95efee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Creating PDF version...\n",
      "‚úì markdown package available\n",
      "‚ö†Ô∏è  WeasyPrint not available - trying alternative...\n",
      "‚ö†Ô∏è  PDF generation requires additional tools.\n",
      "   Install with: pip install weasyprint\n",
      "   Or use: pip install pdfkit + install wkhtmltopdf\n",
      "   For now, use the HTML version for printing (browser ‚Üí Print ‚Üí Save as PDF)\n"
     ]
    }
   ],
   "source": [
    "# 3. Create PDF version (for printing)\n",
    "print(\"\\nüìÑ Creating PDF version...\")\n",
    "\n",
    "try:\n",
    "    # Check if markdown package is available\n",
    "    try:\n",
    "        import markdown\n",
    "        print(\"‚úì markdown package available\")\n",
    "    except ImportError:\n",
    "        print(\"Installing markdown...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"markdown\", \"-q\"])\n",
    "        import markdown\n",
    "        print(\"‚úì markdown installed\")\n",
    "    \n",
    "    # Try using weasyprint (best option for HTML‚ÜíPDF)\n",
    "    try:\n",
    "        from weasyprint import HTML\n",
    "        \n",
    "        pdf_path = project_root / 'docs' / 'DATA_CATALOG_RVX.pdf'\n",
    "        HTML(string=full_html).write_pdf(pdf_path)\n",
    "        \n",
    "        print(f\"‚úÖ Saved PDF to: {pdf_path}\")\n",
    "        print(f\"   File size: {pdf_path.stat().st_size / 1024:.2f} KB\")\n",
    "        print(f\"   Ready to print!\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  WeasyPrint not available - trying alternative...\")\n",
    "        \n",
    "        # Alternative: Use pdfkit (requires wkhtmltopdf installed)\n",
    "        try:\n",
    "            import pdfkit\n",
    "            pdf_path = project_root / 'docs' / 'DATA_CATALOG_RVX.pdf'\n",
    "            pdfkit.from_string(full_html, str(pdf_path))\n",
    "            print(f\"‚úÖ Saved PDF to: {pdf_path}\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  PDF generation requires additional tools.\")\n",
    "            print(\"   Install with: pip install weasyprint\")\n",
    "            print(\"   Or use: pip install pdfkit + install wkhtmltopdf\")\n",
    "            print(\"   For now, use the HTML version for printing (browser ‚Üí Print ‚Üí Save as PDF)\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  PDF creation skipped: {e}\")\n",
    "    print(\"   You can print the HTML version from your browser (Cmd+P ‚Üí Save as PDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9daa91ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìö DATA CATALOG OUTPUTS\n",
      "================================================================================\n",
      "\n",
      "Markdown:\n",
      "  üìç /Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/docs/DATA_CATALOG_RVX.md\n",
      "  üìä 66.82 KB\n",
      "  üí° Edit and version control\n",
      "\n",
      "HTML:\n",
      "  üìç /Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/docs/DATA_CATALOG_RVX.html\n",
      "  üìä 103.71 KB\n",
      "  üí° Open in browser, share online\n",
      "\n",
      "PDF:\n",
      "  üìç /Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/docs/DATA_CATALOG_RVX.pdf\n",
      "  üìä 156.26 KB\n",
      "  üí° Print or share as document\n",
      "\n",
      "================================================================================\n",
      "üéâ All done! You have a complete data catalog ready to use.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 4. Summary of outputs\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìö DATA CATALOG OUTPUTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "outputs = [\n",
    "    (\"Markdown\", catalog_path, \"Edit and version control\"),\n",
    "    (\"HTML\", html_path, \"Open in browser, share online\"),\n",
    "]\n",
    "\n",
    "# Check if PDF was created\n",
    "pdf_path = project_root / 'docs' / 'DATA_CATALOG_RVX.pdf'\n",
    "if pdf_path.exists():\n",
    "    outputs.append((\"PDF\", pdf_path, \"Print or share as document\"))\n",
    "\n",
    "for format_name, path, use_case in outputs:\n",
    "    size_kb = path.stat().st_size / 1024\n",
    "    print(f\"\\n{format_name}:\")\n",
    "    print(f\"  üìç {path}\")\n",
    "    print(f\"  üìä {size_kb:.2f} KB\")\n",
    "    print(f\"  üí° {use_case}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ All done! You have a complete data catalog ready to use.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df7e50",
   "metadata": {},
   "source": [
    "## 6. Interactive Data Inspector\n",
    "\n",
    "Browse through DBF files to verify schema and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53fbeedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìã AVAILABLE DBF FILES\n",
      "================================================================================\n",
      "\n",
      "Change the file_index variable below to inspect different files:\n",
      "\n",
      " 0. sdat1_d2024_g2020.dbf                              (4.42 MB, 14097 rows)\n",
      " 1. sdat1_d2024_g2021.dbf                              (4.42 MB, 14097 rows)\n",
      " 2. sdat1_d2024_g2023.dbf                              (4.43 MB, 14101 rows)\n",
      " 3. sdat1_d2024_g2024.dbf                              (4.43 MB, 14101 rows)\n",
      " 4. sdat3_d2023x_g2020.dbf                             (2.38 MB, 14097 rows)\n",
      " 5. sdat3_d2023x_g2021.dbf                             (2.38 MB, 14097 rows)\n",
      " 6. sdat3_d2023x_g2023.dbf                             (2.38 MB, 14101 rows)\n",
      " 7. sdat3_d2023x_g2024.dbf                             (2.38 MB, 14101 rows)\n",
      " 8. sdat4_d2024_g2020.dbf                              (2.60 MB, 14097 rows)\n",
      " 9. sdat4_d2024_g2021.dbf                              (2.60 MB, 14097 rows)\n",
      "10. sdat4_d2024_g2023.dbf                              (2.60 MB, 14101 rows)\n",
      "11. sdat4_d2024_g2024.dbf                              (2.60 MB, 14101 rows)\n",
      "12. sdat5_d2023_g2020.dbf                              (0.55 MB, 14097 rows)\n",
      "13. sdat5_d2023_g2021.dbf                              (0.55 MB, 14097 rows)\n",
      "14. sdat5_d2023_g2023.dbf                              (0.55 MB, 14101 rows)\n",
      "15. sdat5_d2023_g2024.dbf                              (0.55 MB, 14101 rows)\n",
      "16. sdat71_NB2023_grk2020_2020.dbf                     (0.39 MB, 14097 rows)\n",
      "17. sdat7_d20xx_g2020_ikke_pkost.dbf                   (0.66 MB, 14097 rows)\n",
      "18. sdat7_d20xx_g2021_ikke_pkost.dbf                   (0.66 MB, 14097 rows)\n",
      "19. sdat7_d20xx_g2023_ikke_pkost.dbf                   (0.66 MB, 14101 rows)\n",
      "20. sdat7_d20xx_g2024_ikke_pkost.dbf                   (0.66 MB, 14101 rows)\n",
      "21. sdat8_d2024_g2020.dbf                              (0.87 MB, 14097 rows)\n",
      "22. sdat8_d2024_g2021.dbf                              (0.87 MB, 14097 rows)\n",
      "23. sdat8_d2024_g2023.dbf                              (0.87 MB, 14101 rows)\n",
      "24. sdat8_d2024_g2024.dbf                              (0.87 MB, 14101 rows)\n",
      "25. sdat_6_areal_g2020.dbf                             (3.98 MB, 14097 rows)\n",
      "\n",
      "Total: 26 DBF files\n"
     ]
    }
   ],
   "source": [
    "# List all available DBF files\n",
    "print(\"=\"*80)\n",
    "print(\"üìã AVAILABLE DBF FILES\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nChange the file_index variable below to inspect different files:\\n\")\n",
    "\n",
    "dbf_file_list = [f for f in all_files['zonal_register_data'] if f['extension'] == '.dbf']\n",
    "\n",
    "for idx, f in enumerate(dbf_file_list):\n",
    "    print(f\"{idx:2d}. {f['filename']:<50} ({f['size_mb']:.2f} MB, {file_schemas.get(f['relative_path'], {}).get('rows', '?')} rows)\")\n",
    "\n",
    "print(f\"\\nTotal: {len(dbf_file_list)} DBF files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b81ffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': 'sdat1_d2024_g2021.dbf', 'relative_path': 'sdat1_d2024_g2021.dbf', 'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat1_d2024_g2021.dbf', 'size_bytes': 4639259, 'size_mb': 4.42, 'extension': '.dbf'}\n",
      "sdat1_d2024_g2021.dbf (4.42 MB)\n",
      "\n",
      "14097 rows x 41 columns\n",
      "\n",
      "Schema check (columns + DBF type):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Column</th>\n",
       "      <td>GRUNNKRETS</td>\n",
       "      <td>M_0_4</td>\n",
       "      <td>M_5_9</td>\n",
       "      <td>M_10_14</td>\n",
       "      <td>M_15_19</td>\n",
       "      <td>M_20_24</td>\n",
       "      <td>M_25_29</td>\n",
       "      <td>M_30_34</td>\n",
       "      <td>M_35_39</td>\n",
       "      <td>M_40_44</td>\n",
       "      <td>...</td>\n",
       "      <td>K_50_54</td>\n",
       "      <td>K_55_59</td>\n",
       "      <td>K_60_64</td>\n",
       "      <td>K_65_69</td>\n",
       "      <td>K_70_74</td>\n",
       "      <td>K_75_79</td>\n",
       "      <td>K_80_84</td>\n",
       "      <td>K_85_89</td>\n",
       "      <td>K_90_94</td>\n",
       "      <td>K_95_UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBF Type</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2        3        4        5        6   \\\n",
       "Column    GRUNNKRETS  M_0_4  M_5_9  M_10_14  M_15_19  M_20_24  M_25_29   \n",
       "DBF Type           N      N      N        N        N        N        N   \n",
       "\n",
       "               7        8        9   ...       31       32       33       34  \\\n",
       "Column    M_30_34  M_35_39  M_40_44  ...  K_50_54  K_55_59  K_60_64  K_65_69   \n",
       "DBF Type        N        N        N  ...        N        N        N        N   \n",
       "\n",
       "               35       36       37       38       39       40  \n",
       "Column    K_70_74  K_75_79  K_80_84  K_85_89  K_90_94  K_95_UP  \n",
       "DBF Type        N        N        N        N        N        N  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRUNNKRETS</th>\n",
       "      <th>M_0_4</th>\n",
       "      <th>M_5_9</th>\n",
       "      <th>M_10_14</th>\n",
       "      <th>M_15_19</th>\n",
       "      <th>M_20_24</th>\n",
       "      <th>M_25_29</th>\n",
       "      <th>M_30_34</th>\n",
       "      <th>M_35_39</th>\n",
       "      <th>M_40_44</th>\n",
       "      <th>...</th>\n",
       "      <th>K_50_54</th>\n",
       "      <th>K_55_59</th>\n",
       "      <th>K_60_64</th>\n",
       "      <th>K_65_69</th>\n",
       "      <th>K_70_74</th>\n",
       "      <th>K_75_79</th>\n",
       "      <th>K_80_84</th>\n",
       "      <th>K_85_89</th>\n",
       "      <th>K_90_94</th>\n",
       "      <th>K_95_UP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3010101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3010102</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3010103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3010104</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3010105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3010201</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRUNNKRETS  M_0_4  M_5_9  M_10_14  M_15_19  M_20_24  M_25_29  M_30_34  \\\n",
       "0     3010101    0.0    0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1     3010102    3.0    0.0      0.0      0.0     15.0     39.0     27.0   \n",
       "2     3010103    0.0    0.0      0.0      0.0      3.0      5.0      6.0   \n",
       "3     3010104    3.0    0.0      0.0      3.0     45.0     78.0     42.0   \n",
       "4     3010105    4.0    3.0      0.0      4.0     26.0     66.0     55.0   \n",
       "5     3010201    3.0    0.0      0.0      3.0     31.0     75.0     53.0   \n",
       "\n",
       "   M_35_39  M_40_44  ...  K_50_54  K_55_59  K_60_64  K_65_69  K_70_74  \\\n",
       "0      0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "1     29.0     15.0  ...      4.0      3.0      0.0      3.0      5.0   \n",
       "2      5.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
       "3     29.0     12.0  ...      3.0      4.0      0.0      0.0      0.0   \n",
       "4     44.0     20.0  ...      9.0     12.0      3.0      4.0      3.0   \n",
       "5     26.0     11.0  ...      5.0      3.0      5.0      3.0      0.0   \n",
       "\n",
       "   K_75_79  K_80_84  K_85_89  K_90_94  K_95_UP  \n",
       "0      0.0      0.0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0      0.0      0.0  \n",
       "3      3.0      0.0      0.0      0.0      0.0  \n",
       "4      0.0      0.0      0.0      0.0      0.0  \n",
       "5      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[6 rows x 41 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change this number to inspect different files (0 to 25)\n",
    "file_index = 1\n",
    "\n",
    "# Load and display\n",
    "selected = dbf_file_list[file_index]\n",
    "print(selected)\n",
    "table = DBF(selected['full_path'], encoding='latin-1')\n",
    "df = pd.DataFrame(list(table))\n",
    "\n",
    "print(f\"{selected['filename']} ({selected['size_mb']:.2f} MB)\\n\")\n",
    "print(f\"{df.shape[0]} rows x {df.shape[1]} columns\\n\")\n",
    "\n",
    "# Generic schema check: column names and DBF types (2-row table)\n",
    "row_names = [field.name for field in table.fields]\n",
    "row_types = [field.type for field in table.fields]\n",
    "\n",
    "schema_check = pd.DataFrame([row_names, row_types], index=[\"Column\", \"DBF Type\"])\n",
    "print(\"Schema check (columns + DBF type):\")\n",
    "display(schema_check)\n",
    "\n",
    "# Raw preview\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6606996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'sdat1_d2024_g2020.dbf',\n",
       "  'relative_path': 'sdat1_d2024_g2020.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat1_d2024_g2020.dbf',\n",
       "  'size_bytes': 4639259,\n",
       "  'size_mb': 4.42,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat1_d2024_g2021.dbf',\n",
       "  'relative_path': 'sdat1_d2024_g2021.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat1_d2024_g2021.dbf',\n",
       "  'size_bytes': 4639259,\n",
       "  'size_mb': 4.42,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat1_d2024_g2023.dbf',\n",
       "  'relative_path': 'sdat1_d2024_g2023.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat1_d2024_g2023.dbf',\n",
       "  'size_bytes': 4640575,\n",
       "  'size_mb': 4.43,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat1_d2024_g2024.dbf',\n",
       "  'relative_path': 'sdat1_d2024_g2024.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat1_d2024_g2024.dbf',\n",
       "  'size_bytes': 4640575,\n",
       "  'size_mb': 4.43,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat3_d2023x_g2020.dbf',\n",
       "  'relative_path': 'sdat3_d2023x_g2020.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat3_d2023x_g2020.dbf',\n",
       "  'size_bytes': 2495779,\n",
       "  'size_mb': 2.38,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat3_d2023x_g2021.dbf',\n",
       "  'relative_path': 'sdat3_d2023x_g2021.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat3_d2023x_g2021.dbf',\n",
       "  'size_bytes': 2495779,\n",
       "  'size_mb': 2.38,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat3_d2023x_g2023.dbf',\n",
       "  'relative_path': 'sdat3_d2023x_g2023.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat3_d2023x_g2023.dbf',\n",
       "  'size_bytes': 2496487,\n",
       "  'size_mb': 2.38,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat3_d2023x_g2024.dbf',\n",
       "  'relative_path': 'sdat3_d2023x_g2024.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat3_d2023x_g2024.dbf',\n",
       "  'size_bytes': 2496487,\n",
       "  'size_mb': 2.38,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat4_d2024_g2020.dbf',\n",
       "  'relative_path': 'sdat4_d2024_g2020.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat4_d2024_g2020.dbf',\n",
       "  'size_bytes': 2721523,\n",
       "  'size_mb': 2.6,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat4_d2024_g2021.dbf',\n",
       "  'relative_path': 'sdat4_d2024_g2021.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat4_d2024_g2021.dbf',\n",
       "  'size_bytes': 2721523,\n",
       "  'size_mb': 2.6,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat4_d2024_g2023.dbf',\n",
       "  'relative_path': 'sdat4_d2024_g2023.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat4_d2024_g2023.dbf',\n",
       "  'size_bytes': 2722295,\n",
       "  'size_mb': 2.6,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat4_d2024_g2024.dbf',\n",
       "  'relative_path': 'sdat4_d2024_g2024.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat4_d2024_g2024.dbf',\n",
       "  'size_bytes': 2722295,\n",
       "  'size_mb': 2.6,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat5_d2023_g2020.dbf',\n",
       "  'relative_path': 'sdat5_d2023_g2020.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat5_d2023_g2020.dbf',\n",
       "  'size_bytes': 578171,\n",
       "  'size_mb': 0.55,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat5_d2023_g2021.dbf',\n",
       "  'relative_path': 'sdat5_d2023_g2021.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat5_d2023_g2021.dbf',\n",
       "  'size_bytes': 578171,\n",
       "  'size_mb': 0.55,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat5_d2023_g2023.dbf',\n",
       "  'relative_path': 'sdat5_d2023_g2023.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat5_d2023_g2023.dbf',\n",
       "  'size_bytes': 578335,\n",
       "  'size_mb': 0.55,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat5_d2023_g2024.dbf',\n",
       "  'relative_path': 'sdat5_d2023_g2024.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat5_d2023_g2024.dbf',\n",
       "  'size_bytes': 578335,\n",
       "  'size_mb': 0.55,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat71_NB2023_grk2020_2020.dbf',\n",
       "  'relative_path': 'sdat71_NB2023_grk2020_2020.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat71_NB2023_grk2020_2020.dbf',\n",
       "  'size_bytes': 408975,\n",
       "  'size_mb': 0.39,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat7_d20xx_g2020_ikke_pkost.dbf',\n",
       "  'relative_path': 'sdat7_d20xx_g2020_ikke_pkost.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat7_d20xx_g2020_ikke_pkost.dbf',\n",
       "  'size_bytes': 690979,\n",
       "  'size_mb': 0.66,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat7_d20xx_g2021_ikke_pkost.dbf',\n",
       "  'relative_path': 'sdat7_d20xx_g2021_ikke_pkost.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat7_d20xx_g2021_ikke_pkost.dbf',\n",
       "  'size_bytes': 690979,\n",
       "  'size_mb': 0.66,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat7_d20xx_g2023_ikke_pkost.dbf',\n",
       "  'relative_path': 'sdat7_d20xx_g2023_ikke_pkost.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat7_d20xx_g2023_ikke_pkost.dbf',\n",
       "  'size_bytes': 691175,\n",
       "  'size_mb': 0.66,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat7_d20xx_g2024_ikke_pkost.dbf',\n",
       "  'relative_path': 'sdat7_d20xx_g2024_ikke_pkost.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat7_d20xx_g2024_ikke_pkost.dbf',\n",
       "  'size_bytes': 691175,\n",
       "  'size_mb': 0.66,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat8_d2024_g2020.dbf',\n",
       "  'relative_path': 'sdat8_d2024_g2020.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat8_d2024_g2020.dbf',\n",
       "  'size_bytes': 916595,\n",
       "  'size_mb': 0.87,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat8_d2024_g2021.dbf',\n",
       "  'relative_path': 'sdat8_d2024_g2021.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat8_d2024_g2021.dbf',\n",
       "  'size_bytes': 916595,\n",
       "  'size_mb': 0.87,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat8_d2024_g2023.dbf',\n",
       "  'relative_path': 'sdat8_d2024_g2023.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat8_d2024_g2023.dbf',\n",
       "  'size_bytes': 916855,\n",
       "  'size_mb': 0.87,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat8_d2024_g2024.dbf',\n",
       "  'relative_path': 'sdat8_d2024_g2024.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat8_d2024_g2024.dbf',\n",
       "  'size_bytes': 916855,\n",
       "  'size_mb': 0.87,\n",
       "  'extension': '.dbf'},\n",
       " {'filename': 'sdat_6_areal_g2020.dbf',\n",
       "  'relative_path': 'sdat_6_areal_g2020.dbf',\n",
       "  'full_path': '/Users/anderskielland/Documents/Synthetic data/code/synthetic-lab/data/raw/population/rvx/zonal_register_data/sdat_6_areal_g2020.dbf',\n",
       "  'size_bytes': 4173386,\n",
       "  'size_mb': 3.98,\n",
       "  'extension': '.dbf'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbf_file_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_synthetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
